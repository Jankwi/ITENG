{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0020fc5d-b2ae-4580-935e-05ceba239517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20f40cd-b770-40bd-832d-3f3e95a9c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    print(data.shape)\n",
    "    tensor = torch.tensor(data.values)\n",
    "    tensor = tensor.float()\n",
    "    return tensor\n",
    "def normalize(X):\n",
    "    return X/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1830f3fd-a136-438c-b103-a626b3d7596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rand(a, b):\n",
    "    X = torch.rand(a, b)\n",
    "    return (2*X-1)\n",
    "def init_params(layers_dims):\n",
    "    params = dict()\n",
    "    for i in range(1, len(layers_dims)):\n",
    "        print(i)\n",
    "        params['W' + str(i)] = custom_rand(layers_dims[i-1], layers_dims[i])\n",
    "        params['b' + str(i)] = custom_rand(1, layers_dims[i])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21f92f9-2afe-4cd4-b0da-e6a709f0554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    Z = 1/(1 + torch.exp(-X))\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52cf4998-b42d-407f-9ee2-9bed6746a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grads_on(params):\n",
    "    for key in params:\n",
    "        params[key].requires_grad = True\n",
    "    return params\n",
    "def update_params(params, step_size):\n",
    "    for key in params:\n",
    "        with torch.no_grad():\n",
    "            if(params[key].requires_grad == False):\n",
    "                print(\"ERROOOOOOOOOORRR REQUIRES GRAD SET TO 0\")\n",
    "            params[key] -= step_size * params[key].grad\n",
    "            params[key].grad.zero_()\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54bacfe5-c5f0-4f97-aab5-2e86f7eaa08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration(X, Y, params, L, step_size, print_cost):\n",
    "    params = grads_on(params)\n",
    "    A = X\n",
    "    m = X.shape[0]\n",
    "    for l in range(1, L):\n",
    "        Z = A@params['W' + str(l)] + params['b' + str(l)]\n",
    "        A = torch.tanh(Z)\n",
    "    Z = A@params['W' + str(L)] + params['b' + str(L)]\n",
    "    A = sigmoid(Z)\n",
    "    A = torch.clamp(A, min=1e-8)\n",
    "    A = torch.clamp(A, max=1 - 1e-8)\n",
    "    loss_table = -(Y*torch.log(A) + (1-Y)*torch.log(1-A))\n",
    "    cost = loss_table.sum()/m\n",
    "    if print_cost:\n",
    "        print(\"THE CURRENT COST IS \", cost.item())\n",
    "   # with torch.autograd.detect_anomaly():\n",
    "    cost.backward()\n",
    "    return update_params(params, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ee832d-6d16-46a6-812d-977f7d113e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, params, L, str_type):\n",
    "    A = X\n",
    "    m = X.shape[0]\n",
    "    for l in range(1, L):\n",
    "        Z = A@params['W' + str(l)] + params['b' + str(l)]\n",
    "        A = torch.tanh(Z)\n",
    "    Z = A@params['W' + str(L)] + params['b' + str(L)]\n",
    "    A = sigmoid(Z)\n",
    "    #print(\"AAAAAAAAAAAA \", A)\n",
    "    \n",
    "    loss_table = -(Y*torch.log(A) + (1-Y)*torch.log(1-A))\n",
    "    cost = loss_table.sum()/m\n",
    "    Y_hat = torch.ceil(A/0.5) - 1\n",
    "    incorrect = torch.abs(Y_hat - Y)\n",
    "    gg = m - incorrect.sum()\n",
    "    #print(\"THE TESTING COST IS \", cost.item())\n",
    "    #print(\"The Model made \", gg.item(), \" good predictions\")\n",
    "    print(\"(\", 100*gg.item()/m, \"%\", str_type,\"accuracy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da8765e7-fd38-4a08-976f-ecfa87707d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [780, 60, 50, 40, 1]\n",
    "params = init_params(layers_dims)\n",
    "#print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea41b4a-9fff-4141-8bfe-a5ab2f81184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 780)\n",
      "(2700, 1)\n",
      "(2000, 780)\n",
      "(2000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X = import_data(\"train_X.csv\")\n",
    "train_Y = import_data(\"train_Y.csv\")\n",
    "test_X = import_data(\"test_X.csv\")\n",
    "test_Y = import_data(\"test_Y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c03c0f90-86d9-4332-983f-f3851220008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE CURRENT COST IS  1.6185338497161865\n"
     ]
    }
   ],
   "source": [
    "params = iteration(train_X, train_Y, params, len(layers_dims)-1, 0.000001, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac19dbe-d1c3-4b82-a886-83df7e0b737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH  0\n",
      "THE CURRENT COST IS  0.029540836811065674\n",
      "( 99.96296296296296 % training accuracy)\n",
      "( 59.3 % testing accuracy)\n",
      "EPOCH  500\n",
      "THE CURRENT COST IS  0.028237968683242798\n",
      "( 99.96296296296296 % training accuracy)\n",
      "( 59.4 % testing accuracy)\n",
      "EPOCH  1000\n",
      "THE CURRENT COST IS  0.02702975831925869\n",
      "( 99.96296296296296 % training accuracy)\n",
      "( 59.4 % testing accuracy)\n",
      "EPOCH  1500\n",
      "THE CURRENT COST IS  0.025906739756464958\n",
      "( 99.96296296296296 % training accuracy)\n",
      "( 59.35 % testing accuracy)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m----> 4\u001b[0m params \u001b[38;5;241m=\u001b[39m iteration(train_X, train_Y, params, \u001b[38;5;28mlen\u001b[39m(layers_dims)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, (i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      6\u001b[0m     predict(train_X, train_Y, params, \u001b[38;5;28mlen\u001b[39m(layers_dims)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 17\u001b[0m, in \u001b[0;36miteration\u001b[1;34m(X, Y, params, L, step_size, print_cost)\u001b[0m\n\u001b[0;32m     15\u001b[0m      \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTHE CURRENT COST IS \u001b[39m\u001b[38;5;124m\"\u001b[39m, cost\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# with torch.autograd.detect_anomaly():\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m  cost\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     18\u001b[0m  \u001b[38;5;28;01mreturn\u001b[39;00m update_params(params, step_size)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    if (i%500 == 0):\n",
    "        print(\"EPOCH \", i)\n",
    "    params = iteration(train_X, train_Y, params, len(layers_dims)-1, 0.01, (i%500 == 0))\n",
    "    if (i%500 == 0):\n",
    "        predict(train_X, train_Y, params, len(layers_dims)-1, \"training\")\n",
    "        predict(test_X, test_Y, params, len(layers_dims)-1, \"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d86e913-5ffa-46d1-a578-c2e52e78bf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 49.85 % testing accuracy)\n"
     ]
    }
   ],
   "source": [
    "predict(test_X, test_Y, params, len(layers_dims)-1, \"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47a7feca-c9f2-4d7d-bbba-7e229c45767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 50.55555555555556 % training accuracy)\n"
     ]
    }
   ],
   "source": [
    "predict(train_X, train_Y, params, len(layers_dims)-1, \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41974865-1816-46d8-a81b-f22bb2225497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': tensor([[ 0.2198, -1.5689,  0.9932,  0.9800, -1.6487, -0.5759, -0.6734,  0.5853,\n",
      "         -0.6414,  1.7244, -0.4189,  0.2592,  0.8190,  0.3963, -0.0483, -1.8152,\n",
      "         -2.0649,  0.3983, -0.1439,  1.7575],\n",
      "        [ 0.3030, -1.8976, -0.9924,  0.7409,  0.4212,  1.9007, -1.6258,  0.3228,\n",
      "         -0.8700,  0.7790,  2.1281, -2.3750, -0.8098,  0.9830,  0.7158,  2.6612,\n",
      "         -0.3050, -1.4291, -0.7385,  1.1685],\n",
      "        [-0.2792,  0.5491,  0.2459,  0.5565, -2.3943, -0.1279,  1.3536,  0.1286,\n",
      "         -0.9898, -1.8017,  0.7438,  0.4507,  0.3602, -0.9842, -1.7351, -0.8938,\n",
      "          2.0893,  1.5970,  2.3250, -2.6720],\n",
      "        [ 0.4286,  0.7944,  0.6225, -0.4071, -0.1884, -2.0657,  0.7032, -2.2832,\n",
      "          0.2781,  1.2793,  1.4199,  0.2574, -0.0996,  0.0588, -0.8438,  0.4220,\n",
      "         -0.1711,  2.5255, -0.6821, -0.9614],\n",
      "        [ 0.6103, -0.0201,  0.8810,  0.4092,  1.8000,  1.1644,  0.6110,  1.4394,\n",
      "         -0.4115,  0.7356, -1.3618,  1.2099,  0.3133,  0.8266, -2.3657,  0.0259,\n",
      "         -1.1427,  1.1846, -1.7129,  2.6126],\n",
      "        [ 0.3349,  1.0819,  1.0099, -0.3288,  0.2190,  2.2827, -1.5834, -1.1918,\n",
      "         -0.3612, -2.0405, -2.0817, -0.5858,  0.2275,  0.5743, -0.0030,  1.0492,\n",
      "          0.0914, -0.0364, -1.3798, -0.3609]], requires_grad=True), 'b1': tensor([[ 1.1094,  0.4303,  0.9199,  0.6615,  1.3657, -1.5697,  0.8506,  0.6686,\n",
      "         -0.9206, -0.3963, -0.6509,  0.3638, -0.1171,  0.7927,  2.5537, -0.8998,\n",
      "          0.8032, -2.9507,  1.6634, -0.8757]], requires_grad=True), 'W2': tensor([[ 8.6244e-01, -5.5505e-01,  1.7360e-01, -6.6248e-01, -6.4631e-01,\n",
      "         -1.0935e+00,  1.7686e-01,  8.0353e-01,  4.1332e-01, -2.0906e-01,\n",
      "          4.0232e-01,  7.7978e-01,  1.0140e+00, -5.0291e-01, -1.9170e-01,\n",
      "          7.2611e-01, -4.7426e-01, -2.5415e-01,  1.6550e-01, -3.4856e-01],\n",
      "        [ 5.5283e-01, -1.9809e+00, -9.3614e-01, -1.1833e+00,  7.6217e-01,\n",
      "         -1.4316e-01,  1.4797e+00,  8.1631e-01,  2.2516e-01, -7.2776e-01,\n",
      "          8.1493e-01,  1.2510e+00,  7.0531e-02, -1.0004e+00, -4.0463e-02,\n",
      "          8.6568e-01, -6.9018e-01,  7.6409e-01,  3.8218e-01,  8.9659e-01],\n",
      "        [ 8.5349e-01, -7.5669e-01,  1.4524e-01,  2.2638e-01, -1.2259e-01,\n",
      "         -3.4391e-03, -7.7238e-01, -8.0230e-01,  9.7015e-01, -1.5820e-01,\n",
      "         -1.0401e-01, -1.8144e-01,  1.2272e+00,  5.7556e-01, -2.5969e-01,\n",
      "         -4.4507e-01,  6.4537e-01, -2.6990e-01, -8.9052e-01, -6.0464e-01],\n",
      "        [-3.7918e-01,  1.6830e-01,  8.9542e-01,  9.6697e-02,  2.9243e-01,\n",
      "         -1.0580e+00, -2.2666e-01,  6.6441e-01, -1.0136e-01, -8.2409e-01,\n",
      "          6.9194e-01, -3.9840e-01,  8.8361e-01,  4.3742e-01,  5.1667e-01,\n",
      "          7.8518e-01,  1.2149e+00,  6.2920e-01, -5.4227e-01, -1.1135e+00],\n",
      "        [ 9.7682e-01, -7.7205e-01, -2.1667e-04, -2.3854e+00, -1.7533e-01,\n",
      "          1.1132e-01, -6.3256e-01,  5.6253e-01, -8.6446e-01,  7.3907e-01,\n",
      "          2.5647e-01, -7.3341e-01,  1.6295e-01,  5.0358e-01, -9.8466e-01,\n",
      "          6.9182e-01,  6.6552e-01, -1.7163e+00, -1.1708e+00,  1.5466e+00],\n",
      "        [-9.6728e-01,  1.4102e+00, -9.9763e-01, -1.5516e+00,  7.1017e-01,\n",
      "          5.1253e-03, -4.1783e-01,  8.1814e-01, -8.7841e-01,  1.8562e-01,\n",
      "         -3.2242e-01, -9.3699e-01, -1.7285e+00,  1.3957e-01,  7.6560e-01,\n",
      "          1.4996e+00,  1.5221e+00, -4.3852e-01, -9.2088e-01,  7.1314e-02],\n",
      "        [-5.1885e-01, -1.0513e+00,  7.8467e-01,  7.7314e-01,  4.6641e-01,\n",
      "          1.0378e-02,  1.8347e+00,  4.2450e-01,  1.2002e+00,  8.8296e-01,\n",
      "          1.3293e+00,  3.4536e-02, -2.6268e-01, -1.2320e-01, -9.0857e-01,\n",
      "         -8.8985e-01, -8.5460e-01, -4.7991e-01,  3.9188e-01,  1.2230e+00],\n",
      "        [ 5.1036e-01,  1.0146e+00, -8.5028e-01,  2.4183e-01,  9.6823e-01,\n",
      "         -2.5807e-01,  4.2108e-01, -1.5578e+00,  1.0541e+00, -1.7202e-01,\n",
      "         -4.9891e-01, -1.4743e+00, -1.2643e+00,  1.0951e+00, -1.0538e+00,\n",
      "          7.2366e-01,  8.3741e-01, -1.1176e+00,  8.0515e-01, -7.2087e-01],\n",
      "        [ 7.1636e-01, -2.1986e-01, -4.3993e-01, -3.7324e-01, -7.6351e-01,\n",
      "          4.5857e-01,  2.8525e-01,  2.8408e-01,  5.1681e-01, -3.4233e-01,\n",
      "         -3.1021e-01,  6.6841e-01, -9.3039e-01,  6.2190e-01,  1.0440e+00,\n",
      "         -1.0190e+00, -1.3731e+00,  5.9557e-01,  5.6130e-01,  2.9170e-01],\n",
      "        [ 5.2766e-01,  1.1613e+00, -9.4991e-01,  8.2187e-01, -9.0349e-01,\n",
      "         -1.6809e-01, -2.0368e+00,  4.9145e-01,  7.7386e-01,  2.8455e-01,\n",
      "          1.2127e+00, -6.4737e-01, -2.0873e-01,  5.0584e-02, -2.0125e+00,\n",
      "         -1.0101e-01, -3.0080e-01,  1.0904e+00, -3.9134e-01, -5.2682e-01],\n",
      "        [-1.1677e+00,  9.1446e-01,  1.2526e+00,  1.8886e+00, -1.2043e+00,\n",
      "          1.4263e+00, -4.6847e-01,  5.3506e-01,  4.4808e-01, -5.7746e-01,\n",
      "         -4.8215e-01, -6.1138e-01,  1.3360e+00, -1.8928e+00, -1.2346e+00,\n",
      "          3.7110e-01,  6.9450e-01,  1.7180e+00,  8.3963e-01,  4.0105e-02],\n",
      "        [-2.2655e-01, -1.1961e+00,  6.4228e-01,  8.3293e-01,  4.7493e-01,\n",
      "         -1.4087e-01,  1.2557e+00, -1.3709e+00, -5.2474e-01,  8.9187e-01,\n",
      "          6.6018e-01,  5.0001e-03, -1.6695e+00,  8.2685e-01, -9.3632e-02,\n",
      "         -4.7636e-01,  2.6096e-02,  5.2322e-01, -5.3605e-02,  1.2201e+00],\n",
      "        [-4.6820e-01,  7.2482e-01, -9.0394e-01, -4.8165e-01,  1.1333e+00,\n",
      "         -6.2702e-01, -2.8812e-02,  2.0643e-01, -8.9400e-01, -1.0173e+00,\n",
      "          5.0920e-01,  1.2205e+00,  2.9700e-01,  6.0899e-01, -6.8099e-01,\n",
      "         -6.6802e-01, -4.8911e-02,  8.8952e-02, -2.1641e-01,  1.5192e-01],\n",
      "        [ 4.5608e-01,  2.4603e-01,  3.4525e-01,  5.5808e-01,  7.0612e-01,\n",
      "          3.4570e-01,  2.1656e-01, -7.6729e-02, -9.2065e-02, -9.9481e-01,\n",
      "         -2.8133e-01, -5.4634e-01, -4.2894e-01,  9.6651e-01,  1.1151e-01,\n",
      "         -6.3882e-01,  6.1576e-02,  4.7216e-01,  6.1545e-01,  3.8052e-01],\n",
      "        [ 1.4043e+00,  5.5093e-01,  1.2365e+00,  4.2524e-01, -1.5853e-01,\n",
      "          7.9226e-01, -9.6019e-01,  2.3998e-01,  1.3359e+00,  2.6716e-01,\n",
      "         -1.9527e+00,  1.0789e+00,  1.4252e+00, -1.0582e-02,  6.4313e-01,\n",
      "          1.1880e+00, -1.6584e+00, -1.7973e+00, -4.4633e-01, -8.5563e-01],\n",
      "        [ 1.0090e+00,  1.2374e+00, -4.5150e-01, -1.3491e+00,  1.1785e-01,\n",
      "          1.2395e+00, -8.9425e-01,  7.1856e-01, -1.0705e+00, -3.7034e-01,\n",
      "         -3.5999e-01, -1.1454e+00,  8.7523e-01, -1.4686e+00,  7.3496e-01,\n",
      "          8.1406e-01,  1.4544e+00,  5.4538e-02,  4.2486e-01, -6.5318e-01],\n",
      "        [-7.7945e-01, -7.9905e-03, -4.9794e-01, -1.1776e-01, -4.3452e-01,\n",
      "         -4.6890e-01,  2.0803e+00,  7.5366e-01, -8.1760e-01,  6.4789e-01,\n",
      "         -6.9115e-01, -1.1989e+00,  7.6694e-01, -1.5628e+00,  7.8652e-01,\n",
      "          2.2453e-01,  4.1605e-01, -1.0108e+00,  1.0374e+00,  3.4942e-01],\n",
      "        [-5.4139e-01, -1.4141e+00, -7.1606e-01,  8.6758e-01,  5.2094e-01,\n",
      "          9.1250e-01,  7.5646e-01,  1.5749e+00, -1.1237e+00,  8.6243e-01,\n",
      "          1.6005e+00,  2.4327e-01, -1.0364e+00,  2.3483e-01, -8.1020e-01,\n",
      "         -1.9185e+00,  1.7388e+00,  2.2957e+00,  3.8730e-01,  8.4349e-01],\n",
      "        [-2.2358e-01, -3.9445e-01,  7.4158e-01,  1.9519e+00, -1.4027e-01,\n",
      "          3.7047e-01,  1.4055e+00, -5.6591e-01,  1.3385e+00, -9.2009e-02,\n",
      "         -4.4973e-01, -3.0026e-01,  9.9185e-01, -4.5293e-01,  9.1783e-01,\n",
      "          7.3926e-01, -1.2600e+00, -1.0596e+00,  1.0687e+00, -1.4121e+00],\n",
      "        [ 9.1360e-01,  1.8519e+00, -1.5065e+00, -8.0142e-01, -6.4977e-01,\n",
      "         -5.9816e-01, -1.9944e+00, -8.7015e-01, -5.9916e-01, -7.8953e-02,\n",
      "          9.0764e-01, -1.4507e+00, -2.0851e+00,  1.4624e+00, -1.4154e+00,\n",
      "         -1.5268e-01, -3.4878e-01, -1.3517e-01, -6.4597e-01,  1.1806e+00]],\n",
      "       requires_grad=True), 'b2': tensor([[ 0.6626,  0.5096,  0.1953,  1.0981, -0.3611,  0.4760, -0.3499, -1.0371,\n",
      "         -0.2282, -0.8214,  1.2437,  1.1371,  0.3918,  0.2759,  0.4344,  0.4284,\n",
      "         -0.4978,  0.5138,  0.7450, -1.2940]], requires_grad=True), 'W3': tensor([[ 0.5374, -1.0848,  1.2942, -0.2810,  0.1929, -0.9628, -0.0891, -0.5803,\n",
      "         -0.6515,  0.9671],\n",
      "        [-0.2594,  0.8813, -1.6377, -0.4472,  0.5635,  2.3192,  0.3532, -0.7684,\n",
      "         -2.8193,  0.3187],\n",
      "        [-0.3872, -1.6766,  1.5922,  1.2087,  0.1296,  0.5415, -0.8819,  0.2213,\n",
      "          0.3299,  0.5973],\n",
      "        [ 2.1466, -1.4833,  2.0165,  2.5801,  0.4361, -0.3592, -0.8529, -0.7927,\n",
      "          0.8346, -0.7189],\n",
      "        [ 1.0719,  0.9276, -0.4393, -0.4031, -1.6638, -0.3982, -0.9117, -0.7974,\n",
      "         -0.1380,  0.4671],\n",
      "        [-0.7195, -0.4010, -1.4131,  1.0683,  0.1973, -1.3101, -0.8522, -0.0250,\n",
      "         -0.9982,  0.0224],\n",
      "        [ 0.9386,  0.6448,  0.8163, -2.6093,  0.3018,  2.3238, -1.2102,  0.5340,\n",
      "          0.0482, -0.7701],\n",
      "        [ 0.7299,  0.5661, -0.5432, -1.4771,  0.7494, -1.9079,  1.1107,  0.8348,\n",
      "         -1.2859, -0.0310],\n",
      "        [-1.4717, -1.3966,  0.9385,  1.4976,  1.3342,  1.9039, -0.4288,  0.6382,\n",
      "          1.0810,  0.4182],\n",
      "        [ 0.1484,  0.0240,  0.0401,  1.2048,  0.3863,  0.5115, -0.2855,  0.9199,\n",
      "          0.1127, -0.6277],\n",
      "        [-1.4738, -0.7925,  1.6164, -1.0074, -0.5179, -0.5981,  0.7570,  0.5579,\n",
      "         -2.2121,  0.5317],\n",
      "        [ 1.5472, -1.7567,  1.1604,  0.6150,  0.6146, -1.7260, -0.8097,  1.0648,\n",
      "          0.7409, -0.2559],\n",
      "        [-2.1250, -0.9879, -0.4207,  2.7410, -0.7021, -1.2851, -0.7381,  0.7075,\n",
      "          1.1576,  0.6248],\n",
      "        [-1.1108,  1.0712,  1.4407,  2.2113, -0.6774,  1.1327,  0.3207,  0.3518,\n",
      "          0.8718,  0.8749],\n",
      "        [ 2.1252,  0.7835, -0.5866,  0.6186, -0.1239, -2.0139, -0.5838, -0.0321,\n",
      "          0.2063, -0.1310],\n",
      "        [ 2.0208, -0.4332, -0.5774,  1.5357,  1.2570,  1.1693,  1.0914,  0.4724,\n",
      "         -0.2361,  0.5324],\n",
      "        [ 0.4659,  0.2342, -0.9892, -1.3777, -1.1130,  1.7822,  0.0335,  0.0422,\n",
      "         -2.1885, -0.0513],\n",
      "        [ 0.9279, -0.3332,  0.0707, -3.3745,  0.3096, -0.4464, -0.7468,  1.3305,\n",
      "         -1.5572,  0.8757],\n",
      "        [-0.5001,  0.4608, -1.4756, -0.2530, -0.0421,  0.2622, -1.4479,  0.6121,\n",
      "          0.0432, -0.3461],\n",
      "        [-1.0029,  1.3928, -0.7931, -1.4582, -0.4011, -2.1424, -0.1139,  0.9450,\n",
      "         -0.7499, -0.6864]], requires_grad=True), 'b3': tensor([[-0.0464, -0.0376,  0.4089,  0.0049,  0.5228,  0.7933, -0.5306, -0.6134,\n",
      "         -1.2256,  0.9178]], requires_grad=True), 'W4': tensor([[-4.2866],\n",
      "        [ 3.3722],\n",
      "        [ 4.7803],\n",
      "        [ 5.7450],\n",
      "        [ 1.9780],\n",
      "        [-5.7494],\n",
      "        [ 3.1634],\n",
      "        [ 1.6817],\n",
      "        [ 4.3326],\n",
      "        [ 1.8275]], requires_grad=True), 'b4': tensor([[1.5447]], requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c117ca6-71b9-4ffd-8d1c-c0f9f550b72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
